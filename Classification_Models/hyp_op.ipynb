{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an example file of us using Talos for hyperparameter optimisation on the diabetes data prediction question"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by loading the data from the github platform using the loadtxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  6.    148.     72.    ...   0.627  50.      1.   ]\n",
      " [  1.     85.     66.    ...   0.351  31.      0.   ]\n",
      " [  8.    183.     64.    ...   0.672  32.      1.   ]\n",
      " ...\n",
      " [  5.    121.     72.    ...   0.245  30.      0.   ]\n",
      " [  1.    126.     60.    ...   0.349  47.      1.   ]\n",
      " [  1.     93.     70.    ...   0.315  23.      0.   ]]\n",
      "(768, 9)\n"
     ]
    }
   ],
   "source": [
    "from numpy import loadtxt #allows to load data from a text file. Documentation here: https://numpy.org/doc/stable/reference/generated/numpy.loadtxt.html\n",
    "\n",
    "dataset = loadtxt('https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv', delimiter=',') #delimiter is what separates the diferent values\n",
    "print(dataset)\n",
    "print(dataset.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we split the data into the x and y variables. x is all the 789 rows but only from column 0 to 7 (first 8 columns). y is the class to which the data belongs - 0 or 1 to mean diabetes or not. So, all the rows (:) but 9th column only (indexed at 8 though) only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output\n",
      "------\n",
      "x shape is: (768, 8) while x type is: <class 'numpy.ndarray'>\n",
      "y shape is: (768,) while y type is: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "x = dataset[:,0:8]\n",
    "y = dataset[:,8]\n",
    "print(f'Output')\n",
    "print(f'------')\n",
    "print(f'x shape is:', x.shape, 'while x type is:', type(x))\n",
    "print(f'y shape is:', y.shape, 'while y type is:', type(y))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we build the classification model. Remember its a deep learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "def diabetes():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, input_dim = 8, activation = 'relu', kernel_initializer = 'normal'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(8, activation = 'relu'))\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use talos to select set some of the parameters that we want to test. Note that we set them up as a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.activations import relu, elu #since these are only available in the library , we have to import the library itself for the model to interpret the dictionary accordingly\n",
    "#The model can interpret the functions on its own if its fed directly, but now we are not feeding it directly from its own internal dictionary, we are feeding it from the dictionary that we created hence need to import it to our dictionary first\n",
    "p = {\n",
    "    'lr':[0.5,5,10],\n",
    "    'hidden_layers': [0,1,2],\n",
    "    'epochs':[20,30,40],\n",
    "    'drop_out_1':[0,0.3,0.8],\n",
    "    'drop_out_2':[0,0.2,0.4],\n",
    "    'first_neuron': [12, 24, 36],\n",
    "    'activation_function_one': ['relu', 'elu'],\n",
    "    'activation_function_two': ['relu', 'elu'],\n",
    "    'batch_size':[10,20]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the same time, the library (talos) allows for us to generate multiple parameters automatically then we can clip them when using the .scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import talos\n",
    "p_auto = talos.autom8.AutoParams().params#this generates a dictionary with several elements that we can then modify using the standard dictionary models or clip at the .scan talos method. Note that rerunning this cell generates a new list of values hence the need to probably have this set up somewhere different\n",
    "p_auto\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will remove certain elements and update certain other ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I want to delete the shapes and network so I define these keys first\n",
    "keys = ['shapes', 'network']\n",
    "\n",
    "#Then initialise a for loop to remove them\n",
    "for key in keys:\n",
    "    p_auto.pop(key, None)\n",
    "p_auto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are updating the model function to include these new parameters. Note that we could have ignored the initial building. We only included it to make the process familiar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diabetes(X_train, y_train, x_val, y_val, params): #note that at the moment, we don't have x_val and y_val. However, it seems like the model building automatically ignores the validation process if it does not find the validation data itself.\n",
    "    model = Sequential()\n",
    "    model.add(Dense(params['first_neuron'], input_dim = 8, activation = 'relu'))\n",
    "    model.add(Dropout(params['drop_out_1']))\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "\n",
    "    #since we want to capture the model output, we need to assign it to a variable that the function will return. A very interesting approach when you have the model built inside a function\n",
    "    out = model.fit(x = x, y = y, validation_data = [x_val, y_val], epochs = params['epochs'], batch_size = params['batch_size'], verbose = 0)\n",
    "\n",
    "    return out, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the talos experimental run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/8748 [01:07<54:54:55, 22.61s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtalos\u001b[39;00m \u001b[39m#this is the .scan method that I wrote about in the paper.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m#the first two arguments make sense. params is the dictionary with the parameters\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m#model is the name of the model that you just built. In our case, we encased our model into a function hence the name of the function. Otherwise, we would have model being model (since that is the name of our model)\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39m#Experiment_name is used to create the experiment's log folder (where the data is stored)\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m t \u001b[39m=\u001b[39m talos\u001b[39m.\u001b[39;49mScan(x \u001b[39m=\u001b[39;49m x, y \u001b[39m=\u001b[39;49m y, params \u001b[39m=\u001b[39;49m p, model \u001b[39m=\u001b[39;49m diabetes, experiment_name \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mdiabetes\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\talos\\scan\\Scan.py:205\u001b[0m, in \u001b[0;36mScan.__init__\u001b[1;34m(self, x, y, params, model, experiment_name, x_val, y_val, val_split, multi_input, random_method, seed, performance_target, fraction_limit, round_limit, time_limit, boolean_limit, reduction_method, reduction_interval, reduction_window, reduction_threshold, reduction_metric, minimize_loss, disable_progress_bar, print_params, clear_session, save_weights, save_models)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[39m# start runtime\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mscan_run\u001b[39;00m \u001b[39mimport\u001b[39;00m scan_run\n\u001b[1;32m--> 205\u001b[0m scan_run(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\talos\\scan\\scan_run.py:26\u001b[0m, in \u001b[0;36mscan_run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[39m# otherwise proceed with next permutation\u001b[39;00m\n\u001b[0;32m     25\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mscan_round\u001b[39;00m \u001b[39mimport\u001b[39;00m scan_round\n\u001b[1;32m---> 26\u001b[0m     \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m scan_round(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m     27\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpbar\u001b[39m.\u001b[39mupdate(\u001b[39m1\u001b[39m)\n\u001b[0;32m     29\u001b[0m \u001b[39m# close progress bar before finishing\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\talos\\scan\\scan_round.py:19\u001b[0m, in \u001b[0;36mscan_round\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[39m# fit the model\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mingest_model\u001b[39;00m \u001b[39mimport\u001b[39;00m ingest_model\n\u001b[1;32m---> 19\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_history, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mround_model \u001b[39m=\u001b[39m ingest_model(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m     20\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mround_history\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_history\u001b[39m.\u001b[39mhistory)\n\u001b[0;32m     22\u001b[0m \u001b[39m# handle logging of results\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\talos\\model\\ingest_model.py:6\u001b[0m, in \u001b[0;36mingest_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mingest_model\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m      3\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''Ingests the model that is input by the user\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39m    through Scan() model paramater.'''\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mx_train,\n\u001b[0;32m      7\u001b[0m                       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49my_train,\n\u001b[0;32m      8\u001b[0m                       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mx_val,\n\u001b[0;32m      9\u001b[0m                       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49my_val,\n\u001b[0;32m     10\u001b[0m                       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mround_params)\n",
      "Cell \u001b[1;32mIn[8], line 4\u001b[0m, in \u001b[0;36mdiabetes\u001b[1;34m(X_train, y_train, x_val, y_val, params)\u001b[0m\n\u001b[0;32m      2\u001b[0m model \u001b[39m=\u001b[39m Sequential()\n\u001b[0;32m      3\u001b[0m model\u001b[39m.\u001b[39madd(Dense(params[\u001b[39m'\u001b[39m\u001b[39mfirst_neuron\u001b[39m\u001b[39m'\u001b[39m], input_dim \u001b[39m=\u001b[39m \u001b[39m8\u001b[39m, activation \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m----> 4\u001b[0m model\u001b[39m.\u001b[39;49madd(Dropout(params[\u001b[39m'\u001b[39;49m\u001b[39mdrop_out_1\u001b[39;49m\u001b[39m'\u001b[39;49m]))\n\u001b[0;32m      5\u001b[0m model\u001b[39m.\u001b[39madd(Dense(\u001b[39m1\u001b[39m, activation \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39msigmoid\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[0;32m      6\u001b[0m model\u001b[39m.\u001b[39mcompile(loss \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mbinary_crossentropy\u001b[39m\u001b[39m'\u001b[39m, optimizer \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m, metrics \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\trackable\\base.py:204\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    203\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 204\u001b[0m   result \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    205\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m previous_value  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\engine\\sequential.py:243\u001b[0m, in \u001b[0;36mSequential.add\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    240\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuilt \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    242\u001b[0m \u001b[39mif\u001b[39;00m set_inputs \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_graph_initialized:\n\u001b[1;32m--> 243\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_init_graph_network(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minputs, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moutputs)\n\u001b[0;32m    244\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_graph_initialized \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    245\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\trackable\\base.py:204\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    203\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 204\u001b[0m   result \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    205\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m previous_value  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\engine\\functional.py:274\u001b[0m, in \u001b[0;36mFunctional._init_graph_network\u001b[1;34m(self, inputs, outputs)\u001b[0m\n\u001b[0;32m    272\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_layer_call_argspecs \u001b[39m=\u001b[39m {}\n\u001b[0;32m    273\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_tracked_trackables:\n\u001b[1;32m--> 274\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_layer_call_argspecs[layer] \u001b[39m=\u001b[39m tf_inspect\u001b[39m.\u001b[39;49mgetfullargspec(\n\u001b[0;32m    275\u001b[0m         layer\u001b[39m.\u001b[39;49mcall\n\u001b[0;32m    276\u001b[0m     )\n\u001b[0;32m    278\u001b[0m \u001b[39m# Build self.input_names and self.output_names.\u001b[39;00m\n\u001b[0;32m    279\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_output_names()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\utils\\tf_inspect.py:286\u001b[0m, in \u001b[0;36mgetfullargspec\u001b[1;34m(obj)\u001b[0m\n\u001b[0;32m    284\u001b[0m     \u001b[39mif\u001b[39;00m d\u001b[39m.\u001b[39mdecorator_argspec \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    285\u001b[0m         \u001b[39mreturn\u001b[39;00m _convert_maybe_argspec_to_fullargspec(d\u001b[39m.\u001b[39mdecorator_argspec)\n\u001b[1;32m--> 286\u001b[0m \u001b[39mreturn\u001b[39;00m _getfullargspec(target)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\inspect.py:1277\u001b[0m, in \u001b[0;36mgetfullargspec\u001b[1;34m(func)\u001b[0m\n\u001b[0;32m   1245\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Get the names and default values of a callable object's parameters.\u001b[39;00m\n\u001b[0;32m   1246\u001b[0m \n\u001b[0;32m   1247\u001b[0m \u001b[39mA tuple of seven things is returned:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1258\u001b[0m \u001b[39m  - wrapper chains defined by __wrapped__ *not* unwrapped automatically\u001b[39;00m\n\u001b[0;32m   1259\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1260\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1261\u001b[0m     \u001b[39m# Re: `skip_bound_arg=False`\u001b[39;00m\n\u001b[0;32m   1262\u001b[0m     \u001b[39m#\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1274\u001b[0m     \u001b[39m# getfullargspec() historically ignored __wrapped__ attributes,\u001b[39;00m\n\u001b[0;32m   1275\u001b[0m     \u001b[39m# so we ensure that remains the case in 3.3+\u001b[39;00m\n\u001b[1;32m-> 1277\u001b[0m     sig \u001b[39m=\u001b[39m _signature_from_callable(func,\n\u001b[0;32m   1278\u001b[0m                                    follow_wrapper_chains\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m   1279\u001b[0m                                    skip_bound_arg\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m   1280\u001b[0m                                    sigcls\u001b[39m=\u001b[39;49mSignature,\n\u001b[0;32m   1281\u001b[0m                                    eval_str\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m   1282\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m ex:\n\u001b[0;32m   1283\u001b[0m     \u001b[39m# Most of the times 'signature' will raise ValueError.\u001b[39;00m\n\u001b[0;32m   1284\u001b[0m     \u001b[39m# But, it can also raise AttributeError, and, maybe something\u001b[39;00m\n\u001b[0;32m   1285\u001b[0m     \u001b[39m# else. So to be fully backwards compatible, we catch all\u001b[39;00m\n\u001b[0;32m   1286\u001b[0m     \u001b[39m# possible exceptions here, and reraise a TypeError.\u001b[39;00m\n\u001b[0;32m   1287\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39munsupported callable\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39mex\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\inspect.py:2401\u001b[0m, in \u001b[0;36m_signature_from_callable\u001b[1;34m(obj, follow_wrapper_chains, skip_bound_arg, globals, locals, eval_str, sigcls)\u001b[0m\n\u001b[0;32m   2396\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39m{!r}\u001b[39;00m\u001b[39m is not a callable object\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(obj))\n\u001b[0;32m   2398\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(obj, types\u001b[39m.\u001b[39mMethodType):\n\u001b[0;32m   2399\u001b[0m     \u001b[39m# In this case we skip the first parameter of the underlying\u001b[39;00m\n\u001b[0;32m   2400\u001b[0m     \u001b[39m# function (usually `self` or `cls`).\u001b[39;00m\n\u001b[1;32m-> 2401\u001b[0m     sig \u001b[39m=\u001b[39m _get_signature_of(obj\u001b[39m.\u001b[39;49m\u001b[39m__func__\u001b[39;49m)\n\u001b[0;32m   2403\u001b[0m     \u001b[39mif\u001b[39;00m skip_bound_arg:\n\u001b[0;32m   2404\u001b[0m         \u001b[39mreturn\u001b[39;00m _signature_bound_method(sig)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\inspect.py:2460\u001b[0m, in \u001b[0;36m_signature_from_callable\u001b[1;34m(obj, follow_wrapper_chains, skip_bound_arg, globals, locals, eval_str, sigcls)\u001b[0m\n\u001b[0;32m   2457\u001b[0m             new_params \u001b[39m=\u001b[39m (first_wrapped_param,) \u001b[39m+\u001b[39m sig_params\n\u001b[0;32m   2458\u001b[0m             \u001b[39mreturn\u001b[39;00m sig\u001b[39m.\u001b[39mreplace(parameters\u001b[39m=\u001b[39mnew_params)\n\u001b[1;32m-> 2460\u001b[0m \u001b[39mif\u001b[39;00m isfunction(obj) \u001b[39mor\u001b[39;00m _signature_is_functionlike(obj):\n\u001b[0;32m   2461\u001b[0m     \u001b[39m# If it's a pure Python function, or an object that is duck type\u001b[39;00m\n\u001b[0;32m   2462\u001b[0m     \u001b[39m# of a Python function (Cython functions, for instance), then:\u001b[39;00m\n\u001b[0;32m   2463\u001b[0m     \u001b[39mreturn\u001b[39;00m _signature_from_function(sigcls, obj,\n\u001b[0;32m   2464\u001b[0m                                     skip_bound_arg\u001b[39m=\u001b[39mskip_bound_arg,\n\u001b[0;32m   2465\u001b[0m                                     \u001b[39mglobals\u001b[39m\u001b[39m=\u001b[39m\u001b[39mglobals\u001b[39m, \u001b[39mlocals\u001b[39m\u001b[39m=\u001b[39m\u001b[39mlocals\u001b[39m, eval_str\u001b[39m=\u001b[39meval_str)\n\u001b[0;32m   2467\u001b[0m \u001b[39mif\u001b[39;00m _signature_is_builtin(obj):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import talos #this is the .scan method that I wrote about in the paper.\n",
    "#the first two arguments make sense. params is the dictionary with the parameters\n",
    "#model is the name of the model that you just built. In our case, we encased our model into a function hence the name of the function. Otherwise, we would have model being model (since that is the name of our model)\n",
    "#Experiment_name is used to create the experiment's log folder (where the data is stored)\n",
    "t = talos.Scan(x = x, y = y, params = p, model = diabetes, experiment_name = 'diabetes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now obtaining the results and saving to a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First, we can get the entire dictionary\n",
    "#These are basically the model iteration and the different model hyperparameters used\n",
    "exp_dict = t.saved_models\n",
    "exp_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can obtain the useful information that we need and save it to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = t.data\n",
    "performance.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick overview? Just obtain the model's best performance depending on the score that matters most to you. Though this is a very unidimensional look at the model performance that I would really recommend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here, we are looking at validation accuracy as our calibrating performance indicator. You want to get the highest validation accuracy hence the .max method that is available in the pandas dataframe. In our case, the highest validation accuracy was 78.78 percent with training time of 25 seconds.\n",
    "performance[performance['val_accuracy'] == performance['val_accuracy'].max()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THEN WE CAN NOW MOVE TO ANALYSING HOW THE MODEL PERFORMED UNDER DIFFERENT HYPERPARAMETERS. THIS IS THE MORE INFORMED AND MORE DETAILED LOOK INTO THE EXPERIMENT. NOTE THAT WE SAVED OUR DATA TO A DATAFRAME. THIS IS WHAT WE WILL BE USING FROM HERE ONWARDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You could opt to do your analysis with the dataframe using pandas.This would, of course, give you more flexibility especially if you are really great with pandas module. However, talos has various inbuilt functions that you could use for analysis as long as you save the experiment's output into a .Analyze datatype using the .Reporting method with the argument parsed being the object you created for the experiment (in my case, this was t). \n",
    "r = talos.Reporting(t)\n",
    "print(r) #.Analyze datatype. But if you print it, its just an object from which you can obtain different bits like dataframe - .data. Read up more on how to save data into/ retrieve data out of objects in python\n",
    "r_dataframe = r.data #to extract to a dataframe (method two)\n",
    "r.high('val_accuracy') #returns highest value in that measurement category. Same as saying .max with the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try and plot the line graph for val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "\n",
    "r.plot_line('val_accuracy')\n",
    "#A bit of detour but when run, error: findfont: Font family 'Geneva' not found pops up. I have looked up several ways to update this to no avail. But generally, it is a line plot that plots val_accuracy against the index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we spent too much time on the previous one, we are now moving to plot a correlation graph. Hopefully the font works now because we need it to make sense of the different parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WE HAVE TRIED USING THE LIBRARY FOR ANALYSIS BUT IT SEEMS LIKE THERE IS A PROBLEM WITH IT. AS SUCH, WE WILL USE THE DATAFRAME TO PERFORM THE DIFFERENT ANALYSES THAT WOULD, OTHERWISE, HAVE BEEN DONE BY THE METHODS IN THE LIBRARY ITSELF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First of all, the r_dataframe contains columns such as start and end which we do not need hence delete. But, we first create a copy of it. We create a deep copy (True) to ensure changes in this dataframe do not affect the original one in case we need it for other purposes\n",
    "r_dataframe_copy = r_dataframe.copy(deep = True)\n",
    "r_dataframe_copy.head(10)\n",
    "#Then we delete the columns that don't matter (non-number columns) using column numbers with first non-index column being column 0\n",
    "r_dataframe_copy.drop(r_dataframe_copy.columns[[0,1, 9, 10]], axis = 1, inplace = True)\n",
    "\n",
    "#Then we generate the correlation matrix\n",
    "corr_matrix = r_dataframe_copy.corr()\n",
    "\n",
    "#Then import seaborn (for the heatmap) and matplotlib (for displaying the labels)\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "\n",
    "#Then perform the plot\n",
    "sn.heatmap(corr_matrix, annot = True) #include annotation\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3b7e9cb8e453d6cda0fe8c8dd13f891a1f09162f0e7c66ffeae7751a7aecf00d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
